{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ddayv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ddayv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random as rd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from nltk import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import nltk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(f):     ## Pre-processando a frase\n",
    "\n",
    "    ## Colocando em minusculo\n",
    "    ## Retirando a pontuaçao\n",
    "    ## Retirando as StopWords\n",
    "    \n",
    "    f = f.lower().replace('\\n', '').replace('-','').replace('#','').replace('.','').replace(',','').replace('!','').replace('r\\n','').replace('  ','').replace('https','').replace('rt','').replace('rn','')\n",
    "    token = RegexpTokenizer(r\"\\w+\")\n",
    "    f = token.tokenize(f)\n",
    "    \n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    new_word = [word for word in f if not word in stop_words]\n",
    "    \n",
    "    return ' '.join(new_word)\n",
    "\n",
    "def remove_user(frase):\n",
    "    frase = re.sub('@\\w+','',frase)\n",
    "    frase = re.sub('{https}[^ ]+','',frase)\n",
    "    frase = re.sub('https\\w+','',frase)\n",
    "    # re.sub('#\\w+','',frase)\n",
    "    return frase\n",
    "\n",
    "def pre_X(frases):\n",
    "    lista = []\n",
    "    \n",
    "    for frase in frases:\n",
    "        lista.append(frase)\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def pre_Y(number):\n",
    "    lista = []\n",
    "    \n",
    "    for numb in number:\n",
    "        lista.append(numb)\n",
    "    \n",
    "    return lista\n",
    "\n",
    "def set_array(frases):\n",
    "    \n",
    "    vocab = []\n",
    "    palavras = []\n",
    "    for frase in frases:\n",
    "        \n",
    "        text_array = remove_user(frase)\n",
    "        text_array = Tokenize(text_array)\n",
    "        text_array = text_array.split(' ')\n",
    "        for i in range(len(text_array)):\n",
    "            vocab.append(text_array[i])\n",
    "        \n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWEETSENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_twitter</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1343</td>\n",
       "      <td>863044774588272640</td>\n",
       "      <td>Que coisa linda! O Programa #encontro estava m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344</td>\n",
       "      <td>865583716088766467</td>\n",
       "      <td>Por mais #Encontro com as Irmãs Galvão, adorei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345</td>\n",
       "      <td>865063232201011201</td>\n",
       "      <td>Mr. CATRA @OficialMrCatra lançando sua nova mú...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1346</td>\n",
       "      <td>864668391008763905</td>\n",
       "      <td>quem viu aquela lutadora modela barbuda tatuad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1347</td>\n",
       "      <td>865572794016378882</td>\n",
       "      <td>Tô passada com esse cara.... quanta merda pode...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>12908</td>\n",
       "      <td>864636619000877056</td>\n",
       "      <td>eu ja to aqui pronto pro #MasterChefBR mas ain...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>12909</td>\n",
       "      <td>863581588713603072</td>\n",
       "      <td>MALUCO! Uma coisa que eu não tenho coragem é e...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>12910</td>\n",
       "      <td>864831041349054464</td>\n",
       "      <td>#MaisVoce @ANAMARIABRAGA  está linda @RedeGlobo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>12911</td>\n",
       "      <td>863042798575951872</td>\n",
       "      <td>Que orgulho de ti, @sportrecife! #Encontro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>12912</td>\n",
       "      <td>864681041541386240</td>\n",
       "      <td>Gente olha o bíceps desse padre #ConversaComBial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          id_twitter  \\\n",
       "0       1343  863044774588272640   \n",
       "1       1344  865583716088766467   \n",
       "2       1345  865063232201011201   \n",
       "3       1346  864668391008763905   \n",
       "4       1347  865572794016378882   \n",
       "...      ...                 ...   \n",
       "11565  12908  864636619000877056   \n",
       "11566  12909  863581588713603072   \n",
       "11567  12910  864831041349054464   \n",
       "11568  12911  863042798575951872   \n",
       "11569  12912  864681041541386240   \n",
       "\n",
       "                                                    text sentiment  \n",
       "0      Que coisa linda! O Programa #encontro estava m...         1  \n",
       "1      Por mais #Encontro com as Irmãs Galvão, adorei...         1  \n",
       "2      Mr. CATRA @OficialMrCatra lançando sua nova mú...         1  \n",
       "3      quem viu aquela lutadora modela barbuda tatuad...         0  \n",
       "4      Tô passada com esse cara.... quanta merda pode...        -1  \n",
       "...                                                  ...       ...  \n",
       "11565  eu ja to aqui pronto pro #MasterChefBR mas ain...        -1  \n",
       "11566  MALUCO! Uma coisa que eu não tenho coragem é e...        -1  \n",
       "11567    #MaisVoce @ANAMARIABRAGA  está linda @RedeGlobo         1  \n",
       "11568         Que orgulho de ti, @sportrecife! #Encontro         1  \n",
       "11569   Gente olha o bíceps desse padre #ConversaComBial         1  \n",
       "\n",
       "[11570 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet= pd.read_csv('export_TweetSentBR.csv')\n",
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove = df_tweet[df_tweet['sentiment'] == '-']\n",
    "df_tweet = df_tweet.drop(df_remove.index)\n",
    "\n",
    "df_tweet['text'] = df_tweet['text'].apply(remove_user)\n",
    "df_tweet['text'] = df_tweet['text'].apply(Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet['sentiment'] = df_tweet['sentiment'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_Tweetsent = df_tweet['text']\n",
    "polarity_ = np.asarray(df_tweet['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11533, 17314)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text = count_vect.transform(text_Tweetsent)\n",
    "\n",
    "X_test_TWEET = tfidf_transformer.transform(X_text) # Aplicando o TF-IDF\n",
    "X_test_TWEET.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"tash-pt.csv\")\n",
    "df1 = df1.dropna()\n",
    "df1 = df1.drop(columns=['id_twitter'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(remove_user)\n",
    "df1['text'] = df1['text'].apply(Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2787, 17314)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_TASH = df1['text']\n",
    "sentiment_ = np.asarray(df1['sentiment'])\n",
    "\n",
    "\n",
    "X_text_TASH = count_vect.transform(text_TASH)\n",
    "\n",
    "X_test_TASH_ = tfidf_transformer.transform(X_text_TASH) # Aplicando o TF-IDF\n",
    "X_test_TASH_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KANSOAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.txt\", sep=',', header=None, names=['text','sentiment'])\n",
    "\n",
    "df_remove = df[df['sentiment'] == '#Inveja'].index\n",
    "df = df.drop(df_remove)\n",
    "\n",
    "df_remove = df[df['sentiment'] == '#Raiva'].index\n",
    "df = df.drop(df_remove)\n",
    "\n",
    "df_remove = df[df['sentiment'] == '#Ironia'].index\n",
    "df = df.drop(df_remove)\n",
    "\n",
    "\n",
    "def binario(termo):\n",
    "    if termo == '#Feliz' or termo == '#Amor':\n",
    "        return 1\n",
    "    elif termo == '#Triste' or termo == '#Chateado':\n",
    "        return 0       \n",
    "    \n",
    "df['sentiment'] = df['sentiment'].apply(binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(remove_user)\n",
    "df['text'] = df['text'].apply(Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9224, 17314)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_KANSOAN = df['text']\n",
    "sentiment = np.asarray(df['sentiment'])\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_KANSOAN = count_vect.fit_transform(text_KANSOAN)\n",
    "X_train_KANSOAN = tfidf_transformer.fit_transform(X_train_KANSOAN) # Aplicando o TF-IDF\n",
    "X_train_KANSOAN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12670, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('./rotulação/TweetsPolitical01 OK OK.xlsx')\n",
    "df2 = pd.read_excel('./rotulação/TweetsPolitical02 OK OK.xlsx')\n",
    "df3 = pd.read_excel('./rotulação/TweetsPolitical03 OK OK.xlsx')\n",
    "df4 = pd.read_excel('./rotulação/TweetsPolitical04 OK OK.xlsx')\n",
    "df5 = pd.read_excel('./rotulação/TweetsPolitical05 OK OK.xlsx')\n",
    "df6 = pd.read_excel('./rotulação/TweetsPolitical06 OK OK.xlsx')\n",
    "df7 = pd.read_excel('./rotulação/TweetsPolitical07 OK OK.xlsx')\n",
    "df8 = pd.read_excel('./rotulação/TweetsPolitical08 OK OK.xlsx')\n",
    "df9 = pd.read_excel('./rotulação/TweetsPolitical09 OK OK.xlsx')\n",
    "df10 = pd.read_excel('./rotulação/TweetsPolitical10 OK OK.xlsx')\n",
    "df11 = pd.read_excel('./rotulação/TweetsPolitical11 OK OK.xlsx')\n",
    "df12 = pd.read_excel('./rotulação/TweetsPolitical12 OK OK.xlsx')\n",
    "df13 = pd.read_excel('./rotulação/TweetsPolitical13 OK OK.xlsx')\n",
    "df14 = pd.read_excel('./rotulação/TweetsPolitical14 OK OK.xlsx')\n",
    "df15 = pd.read_excel('./rotulação/TweetsPolitical15 OK OK.xlsx')\n",
    "\n",
    "lista = [df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15]\n",
    "\n",
    "df_all = pd.concat(lista)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., -1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.drop(df_all[df_all['Polaridade'] == 11].index, inplace=True)\n",
    "df_all.drop(df_all[df_all['Polaridade'] == -2].index, inplace=True)\n",
    "df_all.drop(df_all[df_all['Polaridade'] == 10].index, inplace=True)\n",
    "\n",
    "df_all['Polaridade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Polaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- #CaoNossoDeCadaDia #Novo - Vanessa Mandotti ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Bola pra frente que amanhã é outro dia, outr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Cara de mal? Acho que não... Apenas um corte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"@camaradamae: #PCdoB o Partido da coragem !  ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Polaridade\n",
       "0  - #CaoNossoDeCadaDia #Novo - Vanessa Mandotti ...         0.0\n",
       "1  - Bola pra frente que amanhã é outro dia, outr...         1.0\n",
       "2  - Cara de mal? Acho que não... Apenas um corte...         1.0\n",
       "3  \" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...         1.0\n",
       "4  \"@camaradamae: #PCdoB o Partido da coragem !  ...         1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Tweet'] = df_all['Tweet'].apply(remove_user)\n",
    "df_all['Tweet'] = df_all['Tweet'].apply(Tokenize)\n",
    "polarity = np.asarray(df_all['Polaridade'])\n",
    "Tweet = df_all['Tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12626, 17314)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet = count_vect.transform(Tweet)\n",
    "X_test_UNILEX = tfidf_transformer.transform(Tweet) # Aplicando o TF-IDF\n",
    "X_test_UNILEX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(num):\n",
    "    if num == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "sentiment = df['sentiment'].apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB - TRAIN -> KANSOAN- TEST -> TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TIRAR OS SPLITS , até no treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.36      0.90      0.51      3388\n",
      "           0       0.00      0.00      0.00      2928\n",
      "           1       0.67      0.38      0.49      5217\n",
      "\n",
      "    accuracy                           0.44     11533\n",
      "   macro avg       0.34      0.43      0.33     11533\n",
      "weighted avg       0.41      0.44      0.37     11533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_KANSOAN, sentiment)\n",
    "y_pred = clf.predict(X_test_TWEET)\n",
    "\n",
    "print(classification_report(polarity_,y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB - TRAIN -> KANSOAN - TEST -> UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.87      0.55      4186\n",
      "         0.0       0.00      0.00      0.00      4740\n",
      "         1.0       0.36      0.36      0.36      3700\n",
      "\n",
      "    accuracy                           0.39     12626\n",
      "   macro avg       0.26      0.41      0.30     12626\n",
      "weighted avg       0.24      0.39      0.29     12626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_KANSOAN, sentiment)\n",
    "y_pred = clf.predict(X_test_UNILEX)\n",
    "\n",
    "print(classification_report(polarity,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB - TRAIN -> KANSOAN - TEST -> TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      0.84      0.52       881\n",
      "           0       0.00      0.00      0.00      1018\n",
      "           1       0.41      0.36      0.39       888\n",
      "\n",
      "    accuracy                           0.38      2787\n",
      "   macro avg       0.26      0.40      0.30      2787\n",
      "weighted avg       0.25      0.38      0.29      2787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_KANSOAN, sentiment)\n",
    "y_pred = clf.predict(X_test_TASH_)\n",
    "\n",
    "print(classification_report(sentiment_,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - TRAIN->KANSOAN - TEST-> TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.80      0.51      3388\n",
      "           0       0.00      0.00      0.00      2928\n",
      "           1       0.62      0.52      0.57      5217\n",
      "\n",
      "    accuracy                           0.47     11533\n",
      "   macro avg       0.33      0.44      0.36     11533\n",
      "weighted avg       0.39      0.47      0.41     11533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC().fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_TWEET)\n",
    "\n",
    "print(classification_report(polarity_,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM T KANSOAN T UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.66      0.50      4186\n",
      "         0.0       0.00      0.00      0.00      4740\n",
      "         1.0       0.33      0.53      0.41      3700\n",
      "\n",
      "    accuracy                           0.37     12626\n",
      "   macro avg       0.25      0.39      0.30     12626\n",
      "weighted avg       0.23      0.37      0.29     12626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC().fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_UNILEX)\n",
    "\n",
    "print(classification_report(polarity,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM T KANSOAN T TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      0.69      0.48       881\n",
      "           0       1.00      0.00      0.00      1018\n",
      "           1       0.39      0.51      0.44       888\n",
      "\n",
      "    accuracy                           0.38      2787\n",
      "   macro avg       0.59      0.40      0.31      2787\n",
      "weighted avg       0.61      0.38      0.29      2787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC().fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_TASH_)\n",
    "\n",
    "print(classification_report(sentiment_,y_pred, zero_division=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL T KANSOAN T TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      0.77      0.52      3388\n",
      "           0       0.00      0.00      0.00      2928\n",
      "           1       0.61      0.57      0.59      5217\n",
      "\n",
      "    accuracy                           0.48     11533\n",
      "   macro avg       0.33      0.45      0.37     11533\n",
      "weighted avg       0.39      0.48      0.42     11533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_TWEET)\n",
    "\n",
    "print(classification_report(polarity_,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL T KANSOAN T UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.58      0.50      4186\n",
      "         0.0       0.00      0.00      0.00      4740\n",
      "         1.0       0.31      0.60      0.41      3700\n",
      "\n",
      "    accuracy                           0.37     12626\n",
      "   macro avg       0.25      0.39      0.30     12626\n",
      "weighted avg       0.24      0.37      0.29     12626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_UNILEX)\n",
    "\n",
    "print(classification_report(polarity,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL T KANSOAN T TASH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.69      0.49       881\n",
      "           0       0.00      0.00      0.00      1018\n",
      "           1       0.39      0.51      0.44       888\n",
      "\n",
      "    accuracy                           0.38      2787\n",
      "   macro avg       0.25      0.40      0.31      2787\n",
      "weighted avg       0.24      0.38      0.29      2787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_TASH_)\n",
    "\n",
    "print(classification_report(sentiment_,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = OneHotEncoder(sparse=False)\n",
    "teste_ = one.fit_transform(np.asarray(sentiment).reshape(-1,1))\n",
    "nome = pd.DataFrame(teste_)\n",
    "nome['coluna'] = 0\n",
    "nome.rename(columns={1: 2, 'coluna':1} , inplace=True)\n",
    "Y_KANSOAN = nome[[0,1,2]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(num):\n",
    "    if num == -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "sentiment = df['sentiment'].apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOTALMENT.C T KANSOAN T TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "289/289 [==============================] - 1s 5ms/step - loss: 0.1120 - accuracy: 0.9975\n",
      "Epoch 2/5\n",
      "289/289 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "289/289 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "289/289 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "289/289 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(10, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(1 , activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "y_one = np.asarray(sentiment)\n",
    "y_one_test = one.fit_transform(polarity_.reshape(-1,1))\n",
    "\n",
    "fit = model.fit(X_train_KANSOAN.todense(), y_one, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45      3388\n",
      "           1       0.00      0.00      0.00      2928\n",
      "           2       0.00      0.00      0.00      5217\n",
      "\n",
      "    accuracy                           0.29     11533\n",
      "   macro avg       0.10      0.33      0.15     11533\n",
      "weighted avg       0.09      0.29      0.13     11533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test_TWEET.todense())\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(polarity_.reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50      4186\n",
      "           1       0.00      0.00      0.00      4740\n",
      "           2       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.33     12626\n",
      "   macro avg       0.11      0.33      0.17     12626\n",
      "weighted avg       0.11      0.33      0.17     12626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test_UNILEX.todense())\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(polarity.reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48       881\n",
      "           1       1.00      0.00      0.00      1018\n",
      "           2       1.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.32      2787\n",
      "   macro avg       0.77      0.33      0.16      2787\n",
      "weighted avg       0.78      0.32      0.15      2787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test_TASH_.todense())\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(sentiment_).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1), zero_division=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM T KANSOAN T UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    " max_tokens=15000,\n",
    " output_mode='int',\n",
    " output_sequence_length=len(max(text_KANSOAN )))\n",
    "\n",
    "vocab = set_array(text_KANSOAN )\n",
    "\n",
    "vectorize_layer.adapt(np.unique(vocab))\n",
    "len(vectorize_layer.get_vocabulary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/73 [==============================] - 9s 118ms/step - loss: 0.2826 - accuracy: 0.9959\n",
      "Epoch 2/5\n",
      "73/73 [==============================] - 9s 121ms/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "73/73 [==============================] - 9s 118ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "73/73 [==============================] - 9s 124ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "73/73 [==============================] - 9s 124ms/step - loss: 0.0083 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(vectorize_layer.get_vocabulary()),\n",
    "        output_dim=64,mask_zero=True),\n",
    "    \n",
    "    tf.keras.layers.LSTM(50, activation='relu' ,return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.LSTM(25 , activation='tanh', return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.LSTM(10 , activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "y_one = np.asarray(sentiment)\n",
    "\n",
    "\n",
    "fit = model.fit(np.asarray(pre_X(text_KANSOAN)), y_one, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50      4186\n",
      "           1       0.00      0.00      0.00      4740\n",
      "           2       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.33     12626\n",
      "   macro avg       0.11      0.33      0.17     12626\n",
      "weighted avg       0.11      0.33      0.17     12626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(df_all['Tweet'])))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(polarity).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45      3388\n",
      "           1       0.00      0.00      0.00      2928\n",
      "           2       0.00      0.00      0.00      5217\n",
      "\n",
      "    accuracy                           0.29     11533\n",
      "   macro avg       0.10      0.33      0.15     11533\n",
      "weighted avg       0.09      0.29      0.13     11533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_Tweetsent)))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(polarity_).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48       881\n",
      "           1       0.00      0.00      0.00      1018\n",
      "           2       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.32      2787\n",
      "   macro avg       0.11      0.33      0.16      2787\n",
      "weighted avg       0.10      0.32      0.15      2787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_TASH)))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(sentiment_).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONV1D T KANSOAN T TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0639 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 2.4881e-07 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 2.3968e-07 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 2.3061e-07 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 2.1960e-07 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(vectorize_layer.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    \n",
    "    tf.keras.layers.Conv1D(32,6, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')   \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "y_one = np.asarray(sentiment)\n",
    "\n",
    "\n",
    "fit = model.fit(np.asarray(pre_X(text_KANSOAN)), y_one, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48       881\n",
      "           1       0.00      0.00      0.00      1018\n",
      "           2       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.32      2787\n",
      "   macro avg       0.11      0.33      0.16      2787\n",
      "weighted avg       0.10      0.32      0.15      2787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_TASH)))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(sentiment_).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45      3388\n",
      "           1       0.00      0.00      0.00      2928\n",
      "           2       0.00      0.00      0.00      5217\n",
      "\n",
      "    accuracy                           0.29     11533\n",
      "   macro avg       0.10      0.33      0.15     11533\n",
      "weighted avg       0.09      0.29      0.13     11533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_Tweetsent)))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(polarity_).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50      4186\n",
      "           1       0.00      0.00      0.00      4740\n",
      "           2       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.33     12626\n",
      "   macro avg       0.11      0.33      0.17     12626\n",
      "weighted avg       0.11      0.33      0.17     12626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(df_all['Tweet'])))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(polarity).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDR T KANSOAN T TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.6087 - accuracy: 0.9836\n",
      "Epoch 2/5\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.4226 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "73/73 [==============================] - 2s 24ms/step - loss: 0.2849 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "73/73 [==============================] - 2s 30ms/step - loss: 0.2046 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "73/73 [==============================] - 2s 25ms/step - loss: 0.1555 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(vectorize_layer.get_vocabulary()),\n",
    "        output_dim=1,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1)),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "y_one = np.asarray(sentiment)\n",
    "\n",
    "fit = model.fit(np.asarray(pre_X(text_KANSOAN)), y_one, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45      3388\n",
      "           1       0.00      0.00      0.00      2928\n",
      "           2       0.00      0.00      0.00      5217\n",
      "\n",
      "    accuracy                           0.29     11533\n",
      "   macro avg       0.10      0.33      0.15     11533\n",
      "weighted avg       0.09      0.29      0.13     11533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_Tweetsent)))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(polarity_).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50      4186\n",
      "           1       0.00      0.00      0.00      4740\n",
      "           2       0.00      0.00      0.00      3700\n",
      "\n",
      "    accuracy                           0.33     12626\n",
      "   macro avg       0.11      0.33      0.17     12626\n",
      "weighted avg       0.11      0.33      0.17     12626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(df_all['Tweet'])))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(polarity).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48       881\n",
      "           1       0.00      0.00      0.00      1018\n",
      "           2       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.32      2787\n",
      "   macro avg       0.11      0.33      0.16      2787\n",
      "weighted avg       0.10      0.32      0.15      2787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ddayv\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_TASH)))\n",
    "\n",
    "print(classification_report(np.argmax(one.fit_transform(np.asarray(sentiment_).reshape(-1,1)), axis=1), np.argmax(predicted, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
