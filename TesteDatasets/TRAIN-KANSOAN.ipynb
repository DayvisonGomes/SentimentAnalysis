{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ddayv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ddayv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random as rd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from nltk import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import autokeras as ak\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import nltk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(f):     ## Pre-processando a frase\n",
    "\n",
    "    ## Colocando em minusculo\n",
    "    ## Retirando a pontuaçao\n",
    "    ## Retirando as StopWords\n",
    "    \n",
    "    f = f.lower().replace('\\n', '').replace('-','').replace('#','').replace('.','').replace(',','').replace('!','').replace('r\\n','').replace('  ','').replace('https','').replace('rt','').replace('rn','')\n",
    "    token = RegexpTokenizer(r\"\\w+\")\n",
    "    f = token.tokenize(f)\n",
    "    \n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    new_word = [word for word in f if not word in stop_words]\n",
    "    \n",
    "    return ' '.join(new_word)\n",
    "\n",
    "def remove_user(frase):\n",
    "    frase = re.sub('@\\w+','',frase)\n",
    "    frase = re.sub('{https}[^ ]+','',frase)\n",
    "    frase = re.sub('https\\w+','',frase)\n",
    "    # re.sub('#\\w+','',frase)\n",
    "    return frase\n",
    "\n",
    "def pre_X(frases):\n",
    "    lista = []\n",
    "    \n",
    "    for frase in frases:\n",
    "        lista.append(frase)\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def pre_Y(number):\n",
    "    lista = []\n",
    "    \n",
    "    for numb in number:\n",
    "        lista.append(numb)\n",
    "    \n",
    "    return lista\n",
    "\n",
    "def set_array(frases):\n",
    "    \n",
    "    vocab = []\n",
    "    palavras = []\n",
    "    for frase in frases:\n",
    "        \n",
    "        text_array = remove_user(frase)\n",
    "        text_array = Tokenize(text_array)\n",
    "        text_array = text_array.split(' ')\n",
    "        for i in range(len(text_array)):\n",
    "            vocab.append(text_array[i])\n",
    "        \n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KANSOAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.txt\", sep=',', header=None, names=['text','sentiment'])\n",
    "\n",
    "df_remove = df[df['sentiment'] == '#Inveja'].index\n",
    "df = df.drop(df_remove)\n",
    "\n",
    "df_remove = df[df['sentiment'] == '#Raiva'].index\n",
    "df = df.drop(df_remove)\n",
    "\n",
    "df_remove = df[df['sentiment'] == '#Ironia'].index\n",
    "df = df.drop(df_remove)\n",
    "\n",
    "\n",
    "def binario(termo):\n",
    "    if termo == '#Feliz' or termo == '#Amor':\n",
    "        return 1\n",
    "    elif termo == '#Triste' or termo == '#Chateado':\n",
    "        return 0       \n",
    "    \n",
    "df['sentiment'] = df['sentiment'].apply(binario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(remove_user)\n",
    "df['text'] = df['text'].apply(Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9224, 17314)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_KANSOAN = df['text']\n",
    "sentiment = np.asarray(df['sentiment'])\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_KANSOAN = count_vect.fit_transform(text_KANSOAN)\n",
    "X_train_KANSOAN = tfidf_transformer.fit_transform(X_train_KANSOAN) # Aplicando o TF-IDF\n",
    "X_train_KANSOAN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWEETSENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_twitter</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1343</td>\n",
       "      <td>863044774588272640</td>\n",
       "      <td>Que coisa linda! O Programa #encontro estava m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1344</td>\n",
       "      <td>865583716088766467</td>\n",
       "      <td>Por mais #Encontro com as Irmãs Galvão, adorei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345</td>\n",
       "      <td>865063232201011201</td>\n",
       "      <td>Mr. CATRA @OficialMrCatra lançando sua nova mú...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1346</td>\n",
       "      <td>864668391008763905</td>\n",
       "      <td>quem viu aquela lutadora modela barbuda tatuad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1347</td>\n",
       "      <td>865572794016378882</td>\n",
       "      <td>Tô passada com esse cara.... quanta merda pode...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>12908</td>\n",
       "      <td>864636619000877056</td>\n",
       "      <td>eu ja to aqui pronto pro #MasterChefBR mas ain...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>12909</td>\n",
       "      <td>863581588713603072</td>\n",
       "      <td>MALUCO! Uma coisa que eu não tenho coragem é e...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>12910</td>\n",
       "      <td>864831041349054464</td>\n",
       "      <td>#MaisVoce @ANAMARIABRAGA  está linda @RedeGlobo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>12911</td>\n",
       "      <td>863042798575951872</td>\n",
       "      <td>Que orgulho de ti, @sportrecife! #Encontro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>12912</td>\n",
       "      <td>864681041541386240</td>\n",
       "      <td>Gente olha o bíceps desse padre #ConversaComBial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          id_twitter  \\\n",
       "0       1343  863044774588272640   \n",
       "1       1344  865583716088766467   \n",
       "2       1345  865063232201011201   \n",
       "3       1346  864668391008763905   \n",
       "4       1347  865572794016378882   \n",
       "...      ...                 ...   \n",
       "11565  12908  864636619000877056   \n",
       "11566  12909  863581588713603072   \n",
       "11567  12910  864831041349054464   \n",
       "11568  12911  863042798575951872   \n",
       "11569  12912  864681041541386240   \n",
       "\n",
       "                                                    text sentiment  \n",
       "0      Que coisa linda! O Programa #encontro estava m...         1  \n",
       "1      Por mais #Encontro com as Irmãs Galvão, adorei...         1  \n",
       "2      Mr. CATRA @OficialMrCatra lançando sua nova mú...         1  \n",
       "3      quem viu aquela lutadora modela barbuda tatuad...         0  \n",
       "4      Tô passada com esse cara.... quanta merda pode...        -1  \n",
       "...                                                  ...       ...  \n",
       "11565  eu ja to aqui pronto pro #MasterChefBR mas ain...        -1  \n",
       "11566  MALUCO! Uma coisa que eu não tenho coragem é e...        -1  \n",
       "11567    #MaisVoce @ANAMARIABRAGA  está linda @RedeGlobo         1  \n",
       "11568         Que orgulho de ti, @sportrecife! #Encontro         1  \n",
       "11569   Gente olha o bíceps desse padre #ConversaComBial         1  \n",
       "\n",
       "[11570 rows x 4 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet= pd.read_csv('export_TweetSentBR.csv')\n",
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove = df_tweet[df_tweet['sentiment'] == '-']\n",
    "df_tweet = df_tweet.drop(df_remove.index)\n",
    "df_remove = df_tweet[df_tweet['sentiment'] == '0']\n",
    "df_tweet = df_tweet.drop(df_remove.index)\n",
    "\n",
    "df_tweet['text'] = df_tweet['text'].apply(remove_user)\n",
    "df_tweet['text'] = df_tweet['text'].apply(Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet['sentiment'] = df_tweet['sentiment'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_Tweetsent = df_tweet['text']\n",
    "polarity_ = np.asarray(df_tweet['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8605, 17314)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text = count_vect.transform(text_Tweetsent)\n",
    "\n",
    "X_test_TWEET = tfidf_transformer.transform(X_text) # Aplicando o TF-IDF\n",
    "X_test_TWEET.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"tash-pt.csv\")\n",
    "df1 = df1.dropna()\n",
    "df1 = df1.drop(columns=['id_twitter'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(remove_user)\n",
    "df1['text'] = df1['text'].apply(Tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1769, 17314)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_remove = df1.drop(df1[df1['sentiment'] == 0].index)\n",
    "sentiment_ = np.asarray(df1_remove['sentiment'])\n",
    "text_TASH = df1_remove['text']\n",
    "\n",
    "X_text_TASH = count_vect.transform(text_TASH)\n",
    "\n",
    "X_test_TASH_ = tfidf_transformer.transform(X_text_TASH) # Aplicando o TF-IDF\n",
    "X_test_TASH_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_ = pd.read_excel('./rotulação/TweetsPolitical01 OK OK.xlsx')\n",
    "df2 = pd.read_excel('./rotulação/TweetsPolitical02 OK OK.xlsx')\n",
    "df3 = pd.read_excel('./rotulação/TweetsPolitical03 OK OK.xlsx')\n",
    "df4 = pd.read_excel('./rotulação/TweetsPolitical04 OK OK.xlsx')\n",
    "df5 = pd.read_excel('./rotulação/TweetsPolitical05 OK OK.xlsx')\n",
    "df6 = pd.read_excel('./rotulação/TweetsPolitical06 OK OK.xlsx')\n",
    "df7 = pd.read_excel('./rotulação/TweetsPolitical07 OK OK.xlsx')\n",
    "df8 = pd.read_excel('./rotulação/TweetsPolitical08 OK OK.xlsx')\n",
    "df9 = pd.read_excel('./rotulação/TweetsPolitical09 OK OK.xlsx')\n",
    "df10 = pd.read_excel('./rotulação/TweetsPolitical10 OK OK.xlsx')\n",
    "df11 = pd.read_excel('./rotulação/TweetsPolitical11 OK OK.xlsx')\n",
    "df12 = pd.read_excel('./rotulação/TweetsPolitical12 OK OK.xlsx')\n",
    "df13 = pd.read_excel('./rotulação/TweetsPolitical13 OK OK.xlsx')\n",
    "df14 = pd.read_excel('./rotulação/TweetsPolitical14 OK OK.xlsx')\n",
    "df15 = pd.read_excel('./rotulação/TweetsPolitical15 OK OK.xlsx')\n",
    "lista = [df1_,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_ in lista:\n",
    "    df_.drop(df_[df_['Polaridade']== 0.0].index, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_all = pd.concat(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Polaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>- Bola pra frente que amanhã é outro dia, outr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>- Cara de mal? Acho que não... Apenas um corte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"@camaradamae: #PCdoB o Partido da coragem !  ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"As mais #belas #descobertas ocorrem quando as...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>78</td>\n",
       "      <td>Bom diaa  #SD Moisés Sou Boina Preta e Não Tem...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>79</td>\n",
       "      <td>Sei que leve por divisa esse \"V\" que simboliza...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>80</td>\n",
       "      <td>L'ambiance d'hier au stade c'est grace ao Maca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>81</td>\n",
       "      <td>Mais tarde tem mais SD no Chopp E Cia...hoje é...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>82</td>\n",
       "      <td>Obrigado por tudo Mister Luis Castro,boa sorte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7917 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                              Tweet  Polaridade\n",
       "0         1  - Bola pra frente que amanhã é outro dia, outr...         1.0\n",
       "1         2  - Cara de mal? Acho que não... Apenas um corte...         1.0\n",
       "2         3  \" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...         1.0\n",
       "3         4  \"@camaradamae: #PCdoB o Partido da coragem !  ...         1.0\n",
       "4         5  \"As mais #belas #descobertas ocorrem quando as...         1.0\n",
       "...     ...                                                ...         ...\n",
       "7912     78  Bom diaa  #SD Moisés Sou Boina Preta e Não Tem...         1.0\n",
       "7913     79  Sei que leve por divisa esse \"V\" que simboliza...         1.0\n",
       "7914     80  L'ambiance d'hier au stade c'est grace ao Maca...         1.0\n",
       "7915     81  Mais tarde tem mais SD no Chopp E Cia...hoje é...         1.0\n",
       "7916     82  Obrigado por tudo Mister Luis Castro,boa sorte...         1.0\n",
       "\n",
       "[7917 rows x 3 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Polaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>- Bola pra frente que amanhã é outro dia, outr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>- Cara de mal? Acho que não... Apenas um corte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"@camaradamae: #PCdoB o Partido da coragem !  ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"As mais #belas #descobertas ocorrem quando as...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>78</td>\n",
       "      <td>Bom diaa  #SD Moisés Sou Boina Preta e Não Tem...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7913</th>\n",
       "      <td>79</td>\n",
       "      <td>Sei que leve por divisa esse \"V\" que simboliza...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7914</th>\n",
       "      <td>80</td>\n",
       "      <td>L'ambiance d'hier au stade c'est grace ao Maca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>81</td>\n",
       "      <td>Mais tarde tem mais SD no Chopp E Cia...hoje é...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>82</td>\n",
       "      <td>Obrigado por tudo Mister Luis Castro,boa sorte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7915 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                              Tweet  Polaridade\n",
       "0         1  - Bola pra frente que amanhã é outro dia, outr...         1.0\n",
       "1         2  - Cara de mal? Acho que não... Apenas um corte...         1.0\n",
       "2         3  \" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...         1.0\n",
       "3         4  \"@camaradamae: #PCdoB o Partido da coragem !  ...         1.0\n",
       "4         5  \"As mais #belas #descobertas ocorrem quando as...         1.0\n",
       "...     ...                                                ...         ...\n",
       "7912     78  Bom diaa  #SD Moisés Sou Boina Preta e Não Tem...         1.0\n",
       "7913     79  Sei que leve por divisa esse \"V\" que simboliza...         1.0\n",
       "7914     80  L'ambiance d'hier au stade c'est grace ao Maca...         1.0\n",
       "7915     81  Mais tarde tem mais SD no Chopp E Cia...hoje é...         1.0\n",
       "7916     82  Obrigado por tudo Mister Luis Castro,boa sorte...         1.0\n",
       "\n",
       "[7915 rows x 3 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0     4197\n",
       " 1.0     3715\n",
       " 10.0       1\n",
       " 11.0       1\n",
       "-2.0        1\n",
       "Name: Polaridade, dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Polaridade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove1 = df_all[df_all['Polaridade'] == 11].index\n",
    "df_all = df_all.drop(remove1).reset_index()\n",
    "df_all = df_all.drop(columns=['index','level_0'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove2 = df_all[df_all['Polaridade'] == -2].index\n",
    "df_all = df_all.drop(remove2).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove3 = df_all[df_all['Polaridade'] == 10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(remove3).reset_index()\n",
    "df_all = df_all.drop(columns=['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Polaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Bola pra frente que amanhã é outro dia, outr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Cara de mal? Acho que não... Apenas um corte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"@camaradamae: #PCdoB o Partido da coragem !  ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"As mais #belas #descobertas ocorrem quando as...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>Bom diaa  #SD Moisés Sou Boina Preta e Não Tem...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>Sei que leve por divisa esse \"V\" que simboliza...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909</th>\n",
       "      <td>L'ambiance d'hier au stade c'est grace ao Maca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7910</th>\n",
       "      <td>Mais tarde tem mais SD no Chopp E Cia...hoje é...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>Obrigado por tudo Mister Luis Castro,boa sorte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7912 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Polaridade\n",
       "0     - Bola pra frente que amanhã é outro dia, outr...         1.0\n",
       "1     - Cara de mal? Acho que não... Apenas um corte...         1.0\n",
       "2     \" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...         1.0\n",
       "3     \"@camaradamae: #PCdoB o Partido da coragem !  ...         1.0\n",
       "4     \"As mais #belas #descobertas ocorrem quando as...         1.0\n",
       "...                                                 ...         ...\n",
       "7907  Bom diaa  #SD Moisés Sou Boina Preta e Não Tem...         1.0\n",
       "7908  Sei que leve por divisa esse \"V\" que simboliza...         1.0\n",
       "7909  L'ambiance d'hier au stade c'est grace ao Maca...         1.0\n",
       "7910  Mais tarde tem mais SD no Chopp E Cia...hoje é...         1.0\n",
       "7911  Obrigado por tudo Mister Luis Castro,boa sorte...         1.0\n",
       "\n",
       "[7912 rows x 2 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    4197\n",
       " 1.0    3715\n",
       "Name: Polaridade, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Polaridade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Polaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Bola pra frente que amanhã é outro dia, outr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Cara de mal? Acho que não... Apenas um corte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"@camaradamae: #PCdoB o Partido da coragem !  ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"As mais #belas #descobertas ocorrem quando as...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>Bom diaa  #SD Moisés Sou Boina Preta e Não Tem...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>Sei que leve por divisa esse \"V\" que simboliza...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7909</th>\n",
       "      <td>L'ambiance d'hier au stade c'est grace ao Maca...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7910</th>\n",
       "      <td>Mais tarde tem mais SD no Chopp E Cia...hoje é...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7911</th>\n",
       "      <td>Obrigado por tudo Mister Luis Castro,boa sorte...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7912 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Polaridade\n",
       "0     - Bola pra frente que amanhã é outro dia, outr...         1.0\n",
       "1     - Cara de mal? Acho que não... Apenas um corte...         1.0\n",
       "2     \" #PCdoB O PARTIDO QUE FAZ A DIFERENÇA: LEAL E...         1.0\n",
       "3     \"@camaradamae: #PCdoB o Partido da coragem !  ...         1.0\n",
       "4     \"As mais #belas #descobertas ocorrem quando as...         1.0\n",
       "...                                                 ...         ...\n",
       "7907  Bom diaa  #SD Moisés Sou Boina Preta e Não Tem...         1.0\n",
       "7908  Sei que leve por divisa esse \"V\" que simboliza...         1.0\n",
       "7909  L'ambiance d'hier au stade c'est grace ao Maca...         1.0\n",
       "7910  Mais tarde tem mais SD no Chopp E Cia...hoje é...         1.0\n",
       "7911  Obrigado por tudo Mister Luis Castro,boa sorte...         1.0\n",
       "\n",
       "[7912 rows x 2 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Tweet'] = df_all['Tweet'].apply(remove_user)\n",
    "df_all['Tweet'] = df_all['Tweet'].apply(Tokenize)\n",
    "polarity = np.asarray(df_all['Polaridade'])\n",
    "Tweet = df_all['Tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7912, 17314)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet = count_vect.transform(Tweet)\n",
    "X_test_UNILEX = tfidf_transformer.transform(Tweet) # Aplicando o TF-IDF\n",
    "X_test_UNILEX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(num):\n",
    "    if num == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "sentiment = df['sentiment'].apply(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB - TRAIN -> KANSOAN- TEST -> TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TIRAR OS SPLITS , até no treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.49      0.90      0.63      3388\n",
      "           1       0.85      0.38      0.53      5217\n",
      "\n",
      "    accuracy                           0.59      8605\n",
      "   macro avg       0.67      0.64      0.58      8605\n",
      "weighted avg       0.71      0.59      0.57      8605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_KANSOAN, sentiment)\n",
    "y_pred = clf.predict(X_test_TWEET)\n",
    "\n",
    "print(classification_report(polarity_,y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB - TRAIN -> KANSOAN - TEST -> UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.87      0.71      4197\n",
      "         1.0       0.70      0.36      0.47      3715\n",
      "\n",
      "    accuracy                           0.63      7912\n",
      "   macro avg       0.65      0.61      0.59      7912\n",
      "weighted avg       0.65      0.63      0.60      7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_KANSOAN, sentiment)\n",
    "y_pred = clf.predict(X_test_UNILEX)\n",
    "\n",
    "print(classification_report(polarity,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB - TRAIN -> KANSOAN - TEST -> TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.57      0.84      0.68       881\n",
      "           1       0.70      0.36      0.48       888\n",
      "\n",
      "    accuracy                           0.60      1769\n",
      "   macro avg       0.64      0.60      0.58      1769\n",
      "weighted avg       0.64      0.60      0.58      1769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_KANSOAN, sentiment)\n",
    "y_pred = clf.predict(X_test_TASH_)\n",
    "\n",
    "print(classification_report(sentiment_,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - TRAIN->KANSOAN - TEST-> TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.80      0.63      3388\n",
      "           1       0.80      0.52      0.63      5217\n",
      "\n",
      "    accuracy                           0.63      8605\n",
      "   macro avg       0.66      0.66      0.63      8605\n",
      "weighted avg       0.69      0.63      0.63      8605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC().fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_TWEET)\n",
    "\n",
    "print(classification_report(polarity_,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM T KANSOAN T UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.61      0.66      0.63      4197\n",
      "         1.0       0.58      0.53      0.55      3715\n",
      "\n",
      "    accuracy                           0.60      7912\n",
      "   macro avg       0.59      0.59      0.59      7912\n",
      "weighted avg       0.59      0.60      0.59      7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC().fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_UNILEX)\n",
    "\n",
    "print(classification_report(polarity,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM T KANSOAN T TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.69      0.63       881\n",
      "           1       0.62      0.51      0.56       888\n",
      "\n",
      "    accuracy                           0.60      1769\n",
      "   macro avg       0.60      0.60      0.59      1769\n",
      "weighted avg       0.60      0.60      0.59      1769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC().fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_TASH_)\n",
    "\n",
    "print(classification_report(sentiment_,y_pred, zero_division=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL T KANSOAN T TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.77      0.63      3388\n",
      "           1       0.79      0.57      0.66      5217\n",
      "\n",
      "    accuracy                           0.65      8605\n",
      "   macro avg       0.67      0.67      0.65      8605\n",
      "weighted avg       0.69      0.65      0.65      8605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_TWEET)\n",
    "\n",
    "print(classification_report(polarity_,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL T KANSOAN T UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.62      0.58      0.60      4197\n",
      "         1.0       0.56      0.60      0.58      3715\n",
      "\n",
      "    accuracy                           0.59      7912\n",
      "   macro avg       0.59      0.59      0.59      7912\n",
      "weighted avg       0.59      0.59      0.59      7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_UNILEX)\n",
    "\n",
    "print(classification_report(polarity,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL T KANSOAN T TASH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.69      0.63       881\n",
      "           1       0.62      0.51      0.56       888\n",
      "\n",
      "    accuracy                           0.60      1769\n",
      "   macro avg       0.60      0.60      0.60      1769\n",
      "weighted avg       0.60      0.60      0.60      1769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000).fit(X_train_KANSOAN, sentiment) \n",
    "y_pred = clf.predict(X_test_TASH_)\n",
    "\n",
    "print(classification_report(sentiment_,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = OneHotEncoder(sparse=False)\n",
    "teste_ = one.fit_transform(np.asarray(sentiment).reshape(-1,1))\n",
    "nome = pd.DataFrame(teste_)\n",
    "nome['coluna'] = 0\n",
    "nome.rename(columns={1: 2, 'coluna':1} , inplace=True)\n",
    "Y_KANSOAN = nome[[0,1,2]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(num):\n",
    "    if num == -1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "sentiment = df['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_ = np.asarray(df_tweet['sentiment'].apply(func))\n",
    "polarity = np.asarray(df_all['Polaridade'].apply(func))\n",
    "sentiment_ = np.asarray(df1_remove['sentiment'].apply(func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sentiment_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOTALMENT.C T KANSOAN T TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 0.2927 - accuracy: 0.8914 - val_loss: 1.1529 - val_accuracy: 0.5748\n",
      "Epoch 2/5\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 0.0296 - accuracy: 0.9928 - val_loss: 1.1588 - val_accuracy: 0.6353\n",
      "Epoch 3/5\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 1.8518 - val_accuracy: 0.5650\n",
      "Epoch 4/5\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 1.7714 - val_accuracy: 0.6030\n",
      "Epoch 5/5\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 1.8181 - val_accuracy: 0.6157\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(10, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(1 , activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "y_one = np.asarray(sentiment)\n",
    "\n",
    "fit = model.fit(X_train_KANSOAN.todense(), y_one, epochs=5, validation_data=(X_test_TWEET.todense(),polarity_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.81      0.62      3388\n",
      "           1       0.80      0.49      0.61      5217\n",
      "\n",
      "    accuracy                           0.62      8605\n",
      "   macro avg       0.65      0.65      0.62      8605\n",
      "weighted avg       0.68      0.62      0.61      8605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test_TWEET.todense())\n",
    "\n",
    "def ajeita(predicted):\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i,0] >= 0.5:\n",
    "            predicted[i,0] = 1\n",
    "        else:\n",
    "            predicted[i,0] = 0\n",
    "    return predicted\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "print(classification_report(polarity_, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.81      0.70      4197\n",
      "           1       0.66      0.42      0.51      3715\n",
      "\n",
      "    accuracy                           0.63      7912\n",
      "   macro avg       0.64      0.61      0.61      7912\n",
      "weighted avg       0.63      0.63      0.61      7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test_UNILEX.todense())\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(polarity, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.70      0.64       881\n",
      "           1       0.63      0.51      0.56       888\n",
      "\n",
      "    accuracy                           0.60      1769\n",
      "   macro avg       0.61      0.61      0.60      1769\n",
      "weighted avg       0.61      0.60      0.60      1769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test_TASH_.todense())\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(sentiment_, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM T KANSOAN T UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    " max_tokens=15000,\n",
    " output_mode='int',\n",
    " output_sequence_length=len(max(text_KANSOAN )))\n",
    "\n",
    "vocab = set_array(text_KANSOAN )\n",
    "\n",
    "vectorize_layer.adapt(np.unique(vocab))\n",
    "len(vectorize_layer.get_vocabulary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/73 [==============================] - 13s 182ms/step - loss: 0.5994 - accuracy: 0.6573 - val_loss: 0.9047 - val_accuracy: 0.5616\n",
      "Epoch 2/5\n",
      "73/73 [==============================] - 11s 156ms/step - loss: 0.2269 - accuracy: 0.9412 - val_loss: 0.9556 - val_accuracy: 0.5828\n",
      "Epoch 3/5\n",
      "73/73 [==============================] - 12s 159ms/step - loss: 0.0804 - accuracy: 0.9838 - val_loss: 1.1096 - val_accuracy: 0.5933\n",
      "Epoch 4/5\n",
      "73/73 [==============================] - 12s 165ms/step - loss: 0.0414 - accuracy: 0.9931 - val_loss: 1.4133 - val_accuracy: 0.5748\n",
      "Epoch 5/5\n",
      "73/73 [==============================] - 12s 162ms/step - loss: 0.0285 - accuracy: 0.9952 - val_loss: 1.3914 - val_accuracy: 0.5948\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(vectorize_layer.get_vocabulary()),\n",
    "        output_dim=64,mask_zero=True),\n",
    "    \n",
    "    tf.keras.layers.LSTM(50, activation='relu' ,return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.LSTM(25 , activation='tanh', return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.LSTM(10 , activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "y_one = np.asarray(sentiment)\n",
    "\n",
    "\n",
    "fit = model.fit(np.asarray(pre_X(text_KANSOAN)), y_one, epochs=5, batch_size=128,validation_data=(np.asarray(pre_X(df_all['Tweet'])),polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      4197\n",
      "           1       0.57      0.54      0.56      3715\n",
      "\n",
      "    accuracy                           0.59      7912\n",
      "   macro avg       0.59      0.59      0.59      7912\n",
      "weighted avg       0.59      0.59      0.59      7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(df_all['Tweet'])))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(polarity,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.74      0.61      3388\n",
      "           1       0.76      0.54      0.63      5217\n",
      "\n",
      "    accuracy                           0.62      8605\n",
      "   macro avg       0.64      0.64      0.62      8605\n",
      "weighted avg       0.66      0.62      0.62      8605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_Tweetsent)))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(polarity_, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.60       881\n",
      "           1       0.60      0.57      0.58       888\n",
      "\n",
      "    accuracy                           0.59      1769\n",
      "   macro avg       0.59      0.59      0.59      1769\n",
      "weighted avg       0.59      0.59      0.59      1769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_TASH)))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(sentiment_, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONV1D T KANSOAN T TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/73 [==============================] - 2s 28ms/step - loss: 0.5200 - accuracy: 0.7542 - val_loss: 0.9731 - val_accuracy: 0.5557\n",
      "Epoch 2/5\n",
      "73/73 [==============================] - 2s 23ms/step - loss: 0.0836 - accuracy: 0.9719 - val_loss: 1.2929 - val_accuracy: 0.5687\n",
      "Epoch 3/5\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 1.2729 - val_accuracy: 0.5817\n",
      "Epoch 4/5\n",
      "73/73 [==============================] - 2s 26ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 1.3873 - val_accuracy: 0.5811\n",
      "Epoch 5/5\n",
      "73/73 [==============================] - 2s 29ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 1.5689 - val_accuracy: 0.5777\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(vectorize_layer.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    \n",
    "    tf.keras.layers.Conv1D(32,6, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')   \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "y_one = np.asarray(sentiment)\n",
    "\n",
    "\n",
    "fit = model.fit(np.asarray(pre_X(text_KANSOAN)), y_one, epochs=5, batch_size=128, validation_data=(np.asarray(pre_X(text_TASH)),sentiment_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.38      0.47       881\n",
      "           1       0.56      0.77      0.65       888\n",
      "\n",
      "    accuracy                           0.58      1769\n",
      "   macro avg       0.59      0.58      0.56      1769\n",
      "weighted avg       0.59      0.58      0.56      1769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_TASH)))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(sentiment_,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.52      0.55      3388\n",
      "           1       0.71      0.76      0.73      5217\n",
      "\n",
      "    accuracy                           0.67      8605\n",
      "   macro avg       0.65      0.64      0.64      8605\n",
      "weighted avg       0.66      0.67      0.66      8605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_Tweetsent)))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(polarity_, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.29      0.40      4197\n",
      "           1       0.50      0.81      0.62      3715\n",
      "\n",
      "    accuracy                           0.53      7912\n",
      "   macro avg       0.57      0.55      0.51      7912\n",
      "weighted avg       0.57      0.53      0.50      7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(df_all['Tweet'])))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(polarity, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDR T KANSOAN T TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "73/73 [==============================] - 23s 311ms/step - loss: 0.3811 - accuracy: 0.8374 - val_loss: 0.8691 - val_accuracy: 0.6626\n",
      "Epoch 2/5\n",
      "73/73 [==============================] - 22s 307ms/step - loss: 0.0543 - accuracy: 0.9859 - val_loss: 0.9238 - val_accuracy: 0.6690\n",
      "Epoch 3/5\n",
      "73/73 [==============================] - 22s 301ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 1.1566 - val_accuracy: 0.6673\n",
      "Epoch 4/5\n",
      "73/73 [==============================] - 22s 307ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 1.4193 - val_accuracy: 0.6718\n",
      "Epoch 5/5\n",
      "73/73 [==============================] - 25s 341ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 1.5537 - val_accuracy: 0.6653\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorize_layer,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(vectorize_layer.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    \n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    \n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "y_one = np.asarray(sentiment)\n",
    "\n",
    "fit = model.fit(np.asarray(pre_X(text_KANSOAN)), y_one, epochs=5, batch_size=128,validation_data=(np.asarray(pre_X(text_Tweetsent)),polarity_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58      3388\n",
      "           1       0.73      0.72      0.72      5217\n",
      "\n",
      "    accuracy                           0.67      8605\n",
      "   macro avg       0.65      0.65      0.65      8605\n",
      "weighted avg       0.67      0.67      0.67      8605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_Tweetsent)))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(polarity_, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNILEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.46      0.53      4197\n",
      "           1       0.53      0.68      0.59      3715\n",
      "\n",
      "    accuracy                           0.56      7912\n",
      "   macro avg       0.57      0.57      0.56      7912\n",
      "weighted avg       0.58      0.56      0.56      7912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(df_all['Tweet'])))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(polarity,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.47      0.54       881\n",
      "           1       0.58      0.72      0.64       888\n",
      "\n",
      "    accuracy                           0.60      1769\n",
      "   macro avg       0.60      0.60      0.59      1769\n",
      "weighted avg       0.60      0.60      0.59      1769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(np.asarray(pre_X(text_TASH)))\n",
    "\n",
    "predicted = ajeita(predicted)\n",
    "\n",
    "print(classification_report(sentiment_, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
